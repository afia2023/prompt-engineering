| Paper ID | Paper Title | Venue |
|----------|-------------|-------|
| P1 | [Source Code Summarization in the Era of Large Language Models](https://arxiv.org/abs/2407.07959) | ICSE |
| P2 | [Commenting Higher-level Code Unit: Full Code, Reduced Code, or Hierarchical Code Summarization](https://arxiv.org/abs/2503.10737) | arXiv |
| P3 | [DocAgent: A Multi-Agent System for Automated Code Documentation Generation](https://aclanthology.org/2025.acl-demo.44/) | ACL|
| P4 | [Automatic Semantic Augmentation of Language Model Prompts (for Code Summarization)](https://dl.acm.org/doi/10.1145/3597503.3639183) | ICSE  |
| P5 | [Automatic Code Summarization via ChatGPT: How Far Are We?](https://arxiv.org/abs/2305.12865) | arXiv |
| P6 | [RepoSummary: Feature-Oriented Summarization and Documentation Generation for Code Repositories](https://arxiv.org/abs/2510.11039) | arXiv |
| P6 | [Large Language Models are Few-Shot Summarizers: Multi-Intent Comment Generation via In-Context Learning](https://dl.acm.org/doi/10.1145/3597503.3608134) | ICSE |
| P7 | [Natural Is the Best: Model-Agnostic Code Simplification for Pre-trained Large Language Models](https://doi.org/10.1145/3643753) | FSE |
| P8 | [ERNIE-Code: Beyond English-Centric Cross-lingual Pretraining for Programming Languages](https://aclanthology.org/2023.findings-acl.676/) | ACL |
| P9 | [Prompt Engineering or Fine-Tuning: An Empirical Assessment of LLMs for Code](https://www.computer.org/csdl/proceedings-article/msr/2025/018300a490/27vTvjP2rHG) | MSR |
| P10 | [Automatic Code Documentation Generation Using GPT-3](https://dl.acm.org/doi/abs/10.1145/3551349.3559548) | ASE |
| P11 | [InCoder: A Generative Model for Code Infilling and Synthesis](https://arxiv.org/abs/2204.05999) | ICLR |
| P12 | [Exploring Distributional Shifts in Large Language Models for Code Analysis](https://aclanthology.org/2023.emnlp-main.1013/) | EMNLP |
| P13 | [Code Summarization Beyond Function Level](https://ieeexplore.ieee.org/abstract/document/11028203) | LLM4Code @ ICSE 2025 (Workshop) |
| P14 | [Can Developers Prompt? A Controlled Experiment for Code Documentation Generation](https://dl.acm.org/doi/abs/10.1109/ICSME56879.2024.00104) | ICSME |
| P15 | [Attacks and Defenses for Large Language Models on Coding Tasks](https://dl.acm.org/doi/10.1145/3691620.3695297) | ASE |
| P16 | [Few-shot Training LLMs for Project-Specific Code-Summarization](https://dl.acm.org/doi/10.1145/3551349.3559555) | ASE |
| P17 | [DLCoG: A Novel Framework for Dual-Level Code Comment Generation Based on Semantic Segmentation and In-Context Learning](https://www.computer.org/csdl/proceedings-article/icpc/2025/022300a275/27CwQOS94ti) | ICPC |
| P18 | [What Makes Good In-Context Demonstrations for Code Intelligence Tasks with LLMs?](https://ieeexplore.ieee.org/abstract/document/10298329) | ASE |
| P19 | [Project-specific Code Summarization with In-Context Learning](https://dl.acm.org/doi/10.1016/j.jss.2024.112149) | JSS|
| P20 | [Instructive Code Retriever: Learn from Large Language Modelâ€™s Feedback for Code Intelligence Tasks](https://dl.acm.org/doi/abs/10.1145/3691620.3694997) | ASE |
| P21 | [ProConSuL: Project Context for Code Summarization with LLMs](https://aclanthology.org/2024.emnlp-industry.65/) | EMNLP |
| P22 | [Towards Retrieval-Based Neural Code Summarization: A Meta-Learning Approach](https://ieeexplore.ieee.org/abstract/document/10021882) | TSE |
| P23 | [Purpose Enhanced Reasoning through Iterative Prompting: Uncover Latent Robustness of ChatGPT on Code Comprehension](https://www.ijcai.org/proceedings/2024/0720.pdf) | IJCAI |
| P24 | [Hierarchical Repository-Level Code Summarization for Business Applications Using Local LLMs](https://www.computer.org/csdl/proceedings-article/llm4code/2025/261500a145/27ueqNoeCkw) | LLM4Code @ ICSE |
| P25 | [Context Conquers Parameters: Outperforming Proprietary LLM in Commit Message Generation](https://dl.acm.org/doi/10.1109/ICSE55347.2025.00048) | ICSE |
| P26 | [Only Diff Is Not Enough: Generating Commit Messages Leveraging Reasoning and Action of Large Language Model](https://dl.acm.org/doi/10.1145/3643760) | FSE |
| P27 | [Using Large Language Models for Commit Message Generation: A Preliminary Study](https://ieeexplore.ieee.org/abstract/document/10589767) | SANER |
| P28 | [An Empirical Study on Commit Message Generation using LLMs via In-Context Learning](https://arxiv.org/abs/2502.18904) |ICSE |












